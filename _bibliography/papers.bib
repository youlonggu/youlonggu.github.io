---
---

@string{aps = {American Physical Society,}}

@article{quintana_global_2025,
	title = {Global urban visual perception varies across demographics and personalities},
	volume = {2},
	copyright = {2025 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {2731-9997},
	url = {https://www.nature.com/articles/s44284-025-00330-x},
	doi = {10.1038/s44284-025-00330-x},
	abstract = {Understanding people’s preferences is crucial for urban planning, yet current approaches often combine responses from multi-cultural populations, obscuring demographic differences and risking amplifying biases. We conducted a large-scale urban visual perception survey of streetscapes worldwide using street view imagery, examining how demographics—including gender, age, income, education, race and ethnicity, and personality traits—shape perceptions among 1,000 participants with balanced demographics from five countries and 45 nationalities. This dataset, Street Perception Evaluation Considering Socioeconomics, reveals demographic- and personality-based differences across six traditional indicators—safe, lively, wealthy, beautiful, boring, depressing—and four new ones: live nearby, walk, cycle, green. Location-based sentiments further shape these preferences. Machine-learning models trained on existing global datasets tend to overestimate positive indicators and underestimate negative ones compared to human responses, underscoring the need for local context. Our study aspires to rectify the myopic treatment of street perception, which rarely considers demographics or personality traits.},
	number = {11},
	journal = {Nature Cities},
	publisher = {Nature Publishing Group},
	author = {Quintana, Matias and Gu, Youlong and Liang, Xiucheng and Hou, Yujun and Ito, Koichi and Zhu, Yihan and Abdelrahman, Mahmoud and Biljecki, Filip},
	month = nov,
	year = {2025},
	keywords = {Cultural and media studies, Geography, Psychology and behaviour},
	pages = {1092--1106},
	pdf = {Global urban visual perception varies across demographics and personalities.pdf},
  bibtex_show = {true},
  preview = {SPECS.png},
  selected = {true},
}

@article{gu_bayesian_2025,
	title = {A {Bayesian} {Spatiotemporal} {Framework} for {Explaining} {Bus} {Ridership} {Dynamics} in {Singapore}},
	url = {https://osf.io/abyqh/},
	doi = {10.17605/OSF.IO/ABYQH},
	abstract = {Bus networks serve as the backbone of urban public transport, significantly shaping daily mobility patterns. However, few studies have leveraged long-term high spatiotemporal resolution bus data to precisely analyze service demand and urban-scale ridership dynamics. This study proposes a Bayesian hierarchical spatiotemporal modelling framework that integrates structured and unstructured spatial and temporal components. Using Singapore —a city with a dense bus network — as a case study, we evaluate the framework’s effectiveness, identify spatiotemporal trends and ridership hotspots, and assess the influence of key spatial covariables. The findings offer valuable insights for urban and transport planning.},
	journal = {The 19th International Conference on Computational Urban Planning and Urban Management (CUPUM)},
  publisher = {OSF},
	author = {Gu, Youlong and Liu, Haixiao and Lan, Lingsheng and He, Yu and Biljecki, Filip},
	year = {2025},
	keywords = {agent-based modelling, artificial intelligence, cloud cities, data ownership, digital infrastructure, digital twin, land use, machine learning, public data, spatial analysis, sustainability, transportation, urban planning, virtual systems},
	pdf = {A Bayesian Spatiotemporal Framework for Explaining Bus Ridership Dynamics in Singapore.pdf},
  bibtex_show = {true},
  preview = {CUPUM.jpg},
}

@article{cai_can_2025,
	title = {Can a {Large} {Language} {Model} {Assess} {Urban} {Design} {Quality}? {Evaluating} {Walkability} {Metrics} {Across} {Expertise} {Levels}},
	volume = {X-4-W7-2025},
	issn = {2194-9042},
	url = {https://isprs-annals.copernicus.org/articles/X-4-W7-2025/1/2025/},
	doi = {10.5194/isprs-annals-X-4-W7-2025-1-2025},
	abstract = {Urban street environments are vital to supporting human activity in public spaces. The emergence of big data, such as street view images (SVI) combined with multi-modal large language models (MLLM), is transforming how researchers and practitioners investigate, measure, and evaluate semantic and visual elements of urban environments. Considering the low threshold for creating automated evaluative workflows using MLLM, it is crucial to explore both the risks and opportunities associated with these probabilistic models. In particular, the extent to which the integration of expert knowledge can influence the performance of MLLM in the evaluation of the quality of urban design has not been fully explored. This study set out an initial exploration of how integrating more formal and structured representations of expert urban design knowledge (e.g., formal quantifiers and descriptions from existing methods) into the input prompts of an MLLM (ChatGPT-4) can enhance the model\&rsquo;s capability and reliability to evaluate the walkability of built environments using SVIs. We collect walkability metrics through the existing literature and categorise them using relevant ontologies. Then we select a subset of these metrics, used for assessing the subthemes of pedestrian safety and attractiveness, and develop prompts for MLLMs accordingly. We analyse MLLM\&rsquo;s abilities to evaluate SVI walkability subthemes through prompts with multiple levels of clarity and specificity about evaluation criteria. Our experiments demonstrate that MLLMs are capable of providing assessments and interpretations based on general knowledge and can support the automation of imagetext multimodal evaluations. However, they generally provide more optimistic scores and can make mistakes when interpreting the provided metrics, resulting in incorrect evaluations. By integrating expert knowledge, MLLM\&rsquo;s evaluative performance exhibits higher consistency and concentration. Therefore, this paper highlights the importance of formally and effectively integrating domain knowledge into MLLMs for evaluating urban design quality.},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	publisher = {Copernicus GmbH},
	author = {Cai, Chenyi and Kuriyama, Kosuke and Gu, Youlong and Biljecki, Filip and Herthogs, Pieter},
	month = sep,
	year = {2025},
	keywords = {ontology, public space evaluation, semantic and visual elements, street view images, walkability assessment},
	pages = {1--8},
	pdf = {Can a Large Language Model Assess Urban Design Quality Evaluating Walkability Metrics Across Expertise Levels.pdf},
  bibtex_show = {true},
  preview = {LLM.png}
}

@article{gu_designing_2025,
	title = {Designing effective image-based surveys for urban visual perception},
	volume = {260},
	issn = {0169-2046},
	url = {https://www.sciencedirect.com/science/article/pii/S0169204625000751},
	doi = {10.1016/j.landurbplan.2025.105368},
	abstract = {Urban visual perception is important for the human experience in cities, shaped by intertwined characteristics of urban landscapes. By quantifying and explaining these perceptual experiences, researchers can gain insights into human preferences and support decision-making in planning and design. However, past studies have shown inconsistencies in survey design and ambiguities in reporting, leading to concerns about the reliability and reproducibility of results. This study proposes the first comprehensive framework to guide image-based survey design for capturing perceptions of outdoor urban environments across different scenarios, addressing the lack of methodological standardization in current research. We reviewed existing surveys to identify key parameters, conducted comprehensive between-subject and within-subject surveys, and performed statistical analyses to determine best practices for survey design across different contexts. Aiming to set a potential community standard, our study doubles as a blueprint for a reporting protocol for survey designs. Based on the results, we recommend: (1) meeting a minimum of 12 and 22 ratings per image for Likert Scale and Pairwise Comparison studies to reach survey reliability, respectively, and reporting these alongside other survey design parameters to enhance transparency and reproducibility; and (2) when resource allows larger experiments, adopt a ranking method such as Pairwise Comparison to achieve firmer rating results; and (3) using perspective (non-panoramic) images more frequently, as they exhibit comparable overall scores to panoramic images (R mostly {\textgreater}0.7), while being more widely available via crowdsourced sources, supporting their use in large-scale visual perception research.},
	urldate = {2026-01-17},
	journal = {Landscape and Urban Planning},
	author = {Gu, Youlong and Quintana, Matias and Liang, Xiucheng and Ito, Koichi and Yap, Winston and Biljecki, Filip},
	month = aug,
	year = {2025},
	keywords = {Built environment, Street view imagery, Urban perception, Human participants, Survey parameters},
	pages = {105368},
  pdf = {Designing effective image-based surveys for urban visual perception.pdf},
  bibtex_show = {true},
  preview = {survey.png},
  selected = {true},
}

@inproceedings{quintana_my_2024,
	address = {Hangzhou China},
	title = {My street is better than your street: {Towards} data-driven urban planning with visual perception},
	isbn = {979-8-4007-0706-3},
	url = {https://dl.acm.org/doi/10.1145/3671127.3698700},
	doi = {10.1145/3671127.3698700},
	booktitle = {Proceedings of the 11th {ACM} {International} {Conference} on {Systems} for {Energy}-{Efficient} {Buildings}, {Cities}, and {Transportation}},
	publisher = {ACM},
	author = {Quintana, Matias and Gu, Youlong and Biljecki, Filip},
	month = oct,
	year = {2024},
	pages = {221--222},
  bibtex_show = {true},
  preview = {ACM.png}

}


